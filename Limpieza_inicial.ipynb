{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload de Datasets\n",
    "# https://drive.google.com/drive/folders/1oncC_yOvZeNGmC_hLJeavdM4MPq3BkNd\n",
    "\n",
    "# deben estar en la carpeta original_datasets\n",
    "\n",
    "users_ff = pd.read_csv('original_datasets/users_ff.csv')\n",
    "users_ss1 = pd.read_csv('original_datasets/users_ss1.csv')\n",
    "users_ss2 = pd.read_csv('original_datasets/users_ss2.csv')\n",
    "users_ss3 = pd.read_csv('original_datasets/users_ss3.csv')\n",
    "users_ts = pd.read_csv('original_datasets/users_ts.csv')\n",
    "users_humans = pd.read_csv('original_datasets/users_gen.csv')\n",
    "\n",
    "tweets_ff = pd.read_csv('original_datasets/tweets_ff.csv')\n",
    "tweets_ss1 = pd.read_csv('original_datasets/tweets_ss1.csv')\n",
    "tweets_ss2 = pd.read_csv('original_datasets/tweets_ss2.csv')\n",
    "tweets_ss3 = pd.read_csv('original_datasets/tweets_ss3.csv')\n",
    "tweets_ts = pd.read_csv('original_datasets/tweets_ts.csv')\n",
    "tweets_humans = pd.read_csv('original_datasets/tweets_gen.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Agregar columna para categorizar\n",
    "users_ss1.loc[:,'Cat'] = 'SocialSpambot'\n",
    "users_ss2.loc[:,'Cat'] = 'SocialSpambot'\n",
    "users_ss3.loc[:,'Cat'] = 'SocialSpambot'\n",
    "users_ts.loc[:,'Cat'] = 'TraditionalSpambot'\n",
    "users_ff.loc[:,'Cat'] = 'FollowersBot'\n",
    "users_humans.loc[:,'Cat'] = 'Humans'\n",
    "\n",
    "users_ss1.loc[:,'bot'] = True\n",
    "users_ss2.loc[:,'bot'] = True\n",
    "users_ss3.loc[:,'bot'] = True\n",
    "users_ts.loc[:,'bot'] = True\n",
    "users_ff.loc[:,'bot'] = True\n",
    "users_humans.loc[:,'bot'] = False\n",
    "\n",
    "# Limpiar columnas innecesarias\n",
    "users_ss1.drop(columns='test_set_1',inplace=True)\n",
    "users_ss3.drop(columns='test_set_2',inplace=True)\n",
    "users_humans.drop(columns=['test_set_1','test_set_2'],inplace=True)\n",
    "\n",
    "# Concatenar datasets de Usuarios (SocialSpambots & Traditional Spambots)\n",
    "users = pd.concat([users_ss1,users_ss2,users_ss3,users_ts,users_ff,users_humans],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Cero Columns\n",
    "users.drop(columns=['contributors_enabled','follow_request_sent','following','is_translator','notifications',],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_columns = []\n",
    "for x in [users_ss1, users_ss2, users_ss3, users_ts, users_ff, users_humans]:\n",
    "#     print(x.columns.values)\n",
    "    total_columns = np.concatenate((total_columns, x.columns.values))\n",
    "    \n",
    "total_columns = np.unique(np.array(total_columns))\n",
    "dfHasColumns = pd.DataFrame( columns = total_columns)\n",
    "for dfName in ['users_ss1', 'users_ss2', 'users_ss3', 'users_ts', 'users_ff', 'users_humans']:\n",
    "    dataFrame = globals()[dfName]\n",
    "    cols = dataFrame.columns.values\n",
    "    hasCol = [1 if x in(cols) else 0 for x in dfHasColumns.columns.values]\n",
    "    dfHasColumns.loc[dfName] = hasCol\n",
    "dfHasColumns  = dfHasColumns.T\n",
    "dfHasColumns.loc[:,'total'] = dfHasColumns.sum(axis=1)\n",
    "\n",
    "dfHasColumns.sort_values(by='total').head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones de esta tabla:\n",
    "La columna 'crawled_at' no se encuentra en users_ff (Folowers Bot).<br>\n",
    "Esta columna es importante debido a que nos da una idea de la cantidad de meses que ese bot estuvo activo (y nos permite calcular una vida promedio del bot)\n",
    "Hay tres opciones:<br>\n",
    "1 No calcular la cantidad de meses antes que un bot se crea.<br>\n",
    "2 No utilizar ese dataset.<br>\n",
    "3 Asumir la fecha updated que esta presente en todos los casos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display()\n",
    "\n",
    "for x in users_humans.columns.values:\n",
    "    display(\n",
    "        users_humans.loc[:,[x]][users_humans.loc[:,[x]].notnull().values].head(2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar a pkl\n",
    "# users_spam.to_pickle('users_spam.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar columna para categorizar\n",
    "tweets_ss1['Cat'] = 'SocialSpambot'\n",
    "tweets_ss2['Cat'] = 'SocialSpambot'\n",
    "tweets_ss3['Cat'] = 'SocialSpambot'\n",
    "tweets_ts['Cat'] = 'TraditionalSpambot'\n",
    "tweets_ff['Cat'] = 'FollowersBot'\n",
    "tweets_humans['Cat'] = 'Humans'\n",
    "# Concatenar datasets de Usuarios (SocialSpambots & Traditional Spambots)\n",
    "tweets = pd.concat([tweets_ss1,tweets_ss2,tweets_ss3,tweets_ts,tweets_ff,tweets_humans],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['created_at'].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_columns = []\n",
    "for x in [tweets_ss1, tweets_ss2, tweets_ss3, tweets_ts, tweets_ff, tweets_humans]:\n",
    "#     print(x.columns.values)\n",
    "    total_columns = np.concatenate((total_columns, x.columns.values))\n",
    "    \n",
    "total_columns = np.unique(np.array(total_columns))\n",
    "dfHasColumns = pd.DataFrame( columns = total_columns)\n",
    "for dfName in ['tweets_ss1', 'tweets_ss2', 'tweets_ss3', 'tweets_ts', 'tweets_ff', 'tweets_humans']:\n",
    "    dataFrame = globals()[dfName]\n",
    "    cols = dataFrame.columns.values\n",
    "    hasCol = [1 if x in(cols) else 0 for x in dfHasColumns.columns.values]\n",
    "    dfHasColumns.loc[dfName] = hasCol\n",
    "dfHasColumns  = dfHasColumns.T\n",
    "dfHasColumns.loc[:,'total'] = dfHasColumns.sum(axis=1)\n",
    "\n",
    "dfHasColumns.sort_values(by='total').head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets_ss1.shape)\n",
    "print(tweets_ss2.shape)\n",
    "print(tweets_ss3.shape)\n",
    "print(tweets_ts.shape)\n",
    "print(tweets_ff.shape)\n",
    "print(teets_humans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar a pkl\n",
    "# tweets_spam.to_pickle('tweets_spam.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
