{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (7,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Upload de Datasets\n",
    "# https://drive.google.com/drive/folders/1oncC_yOvZeNGmC_hLJeavdM4MPq3BkNd\n",
    "# deben estar en la carpeta original_datasets\n",
    "\n",
    "#users_ff = pd.read_csv('original_datasets/users_ff.csv')   -- No se incluye en el modelo \n",
    "users_ss1 = pd.read_csv('original_datasets/users_ss1.csv')\n",
    "users_ss2 = pd.read_csv('original_datasets/users_ss2.csv')\n",
    "users_ss3 = pd.read_csv('original_datasets/users_ss3.csv')\n",
    "#users_ts = pd.read_csv('original_datasets/users_ts.csv')   -- No se incluye en el modelo \n",
    "users_humans = pd.read_csv('original_datasets/users_gen.csv')\n",
    "\n",
    "# tweets_ff = pd.read_csv('original_datasets/tweets_ff.csv')   -- No se incluye en el modelo \n",
    "tweets_ss1 = pd.read_csv('original_datasets/tweets_ss1.csv')\n",
    "tweets_ss2 = pd.read_csv('original_datasets/tweets_ss2.csv')\n",
    "tweets_ss3 = pd.read_csv('original_datasets/tweets_ss3.csv')\n",
    "# tweets_ts = pd.read_csv('original_datasets/tweets_ts.csv')   -- No se incluye en el modelo \n",
    "tweets_humans = pd.read_csv('original_datasets/tweets_gen.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Asignar labels\n",
    "users_ss1.loc[:,'Cat'] = 'SocialSpambot'\n",
    "users_ss2.loc[:,'Cat'] = 'SocialSpambot'\n",
    "users_ss3.loc[:,'Cat'] = 'SocialSpambot'\n",
    "#users_ts.loc[:,'Cat'] = 'TraditionalSpambot'   -- No se incluye en el modelo \n",
    "#users_ff.loc[:,'Cat'] = 'FollowersBot'   -- No se incluye en el modelo\n",
    "users_humans.loc[:,'Cat'] = 'Humans'\n",
    "tweets_ss1['Cat'] = 'SocialSpambot'\n",
    "tweets_ss2['Cat'] = 'SocialSpambot'\n",
    "tweets_ss3['Cat'] = 'SocialSpambot'\n",
    "#tweets_ts['Cat'] = 'TraditionalSpambot'   -- No se incluye en el modelo\n",
    "#tweets_ff['Cat'] = 'FollowersBot'   -- No se incluye en el modelo\n",
    "tweets_humans['Cat'] = 'Humans'\n",
    "\n",
    "# Crear label binaria 'bot'\n",
    "users_ss1.loc[:,'bot'] = True\n",
    "users_ss2.loc[:,'bot'] = True\n",
    "users_ss3.loc[:,'bot'] = True\n",
    "users_humans.loc[:,'bot'] = False\n",
    "tweets_ss1.loc[:,'bot'] = True\n",
    "tweets_ss2.loc[:,'bot'] = True\n",
    "tweets_ss3.loc[:,'bot'] = True\n",
    "tweets_humans.loc[:,'bot'] = False\n",
    "\n",
    "# Concatenar datasets de USUARIOS (SocialSpambots & Traditional Spambots)\n",
    "users = pd.concat([users_ss1,users_ss2,users_ss3,users_humans],ignore_index=True)\n",
    "\n",
    "# Concatenar datasets de TWEETS (SocialSpambots & Traditional Spambots)\n",
    "tweets = pd.concat([tweets_ss1,tweets_ss2,tweets_ss3,tweets_humans],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>users_ss1</th>\n",
       "      <th>users_ss2</th>\n",
       "      <th>users_ss3</th>\n",
       "      <th>users_humans</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_set_2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_set_1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profile_background_tile</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profile_banner_url</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profile_image_url</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profile_image_url_https</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        users_ss1 users_ss2 users_ss3 users_humans  total\n",
       "test_set_2                      0         0         1            1    2.0\n",
       "test_set_1                      1         0         0            1    2.0\n",
       "Cat                             1         1         1            1    4.0\n",
       "profile_background_tile         1         1         1            1    4.0\n",
       "profile_banner_url              1         1         1            1    4.0\n",
       "profile_image_url               1         1         1            1    4.0\n",
       "profile_image_url_https         1         1         1            1    4.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identificar columnas que no coinciden entre datasets\n",
    "total_columns = []\n",
    "for x in [users_ss1, users_ss2, users_ss3, users_humans]:\n",
    "#     print(x.columns.values)\n",
    "    total_columns = np.concatenate((total_columns, x.columns.values))\n",
    "    \n",
    "total_columns = np.unique(np.array(total_columns))\n",
    "dfHasColumns = pd.DataFrame( columns = total_columns)\n",
    "for dfName in ['users_ss1', 'users_ss2', 'users_ss3', 'users_humans']:\n",
    "    dataFrame = globals()[dfName]\n",
    "    cols = dataFrame.columns.values\n",
    "    hasCol = [1 if x in(cols) else 0 for x in dfHasColumns.columns.values]\n",
    "    dfHasColumns.loc[dfName] = hasCol\n",
    "dfHasColumns  = dfHasColumns.T\n",
    "dfHasColumns.loc[:,'total'] = dfHasColumns.sum(axis=1)\n",
    "\n",
    "dfHasColumns.sort_values(by='total').head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones de esta tabla:\n",
    "La columna 'crawled_at' no se encuentra en users_ff (Folowers Bot).<br>\n",
    "Esta columna es importante debido a que nos da una idea de la cantidad de meses que ese bot estuvo activo (y nos permite calcular una vida promedio del bot)\n",
    "Hay tres opciones:<br>\n",
    "1 No calcular la cantidad de meses antes que un bot se crea.<br>\n",
    "2 No utilizar ese dataset.<br>\n",
    "3 Asumir la fecha updated que esta presente en todos los casos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>updated</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Humans</th>\n",
       "      <td>2016-03-15 16:02:33.520147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SocialSpambot</th>\n",
       "      <td>2016-03-15 15:03:02.455618816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    updated\n",
       "Cat                                        \n",
       "Humans        2016-03-15 16:02:33.520147200\n",
       "SocialSpambot 2016-03-15 15:03:02.455618816"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Promedios de fecha de recolección por categoria\n",
    "a = users[['updated','Cat']]\n",
    "a.updated = pd.to_datetime(a.updated).astype(int)\n",
    "b = a.groupby('Cat').mean()\n",
    "b.updated = pd.to_datetime(b.updated)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2014-05-11 18:06:42.582858496')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(pd.to_datetime(users[users.Cat=='SocialSpambot']['crawled_at']).astype(int).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SocialSpambot     :  2014-05-11 18:06:42.582858496\n",
      "Humans            :  2015-05-01 20:34:44.187679744\n"
     ]
    }
   ],
   "source": [
    "# USERS Promedios de fecha de Recolección por Categoria\n",
    "print('SocialSpambot     : ',pd.to_datetime(pd.to_datetime(users[users.Cat=='SocialSpambot']['crawled_at']).astype(int).mean()))\n",
    "print('Humans            : ',pd.to_datetime(pd.to_datetime(users[users.Cat=='Humans']['crawled_at']).astype(int).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crawled_at</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Humans</th>\n",
       "      <td>2015-05-01 13:16:23.045936896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SocialSpambot</th>\n",
       "      <td>2014-11-13 06:32:37.091956736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 crawled_at\n",
       "Cat                                        \n",
       "Humans        2015-05-01 13:16:23.045936896\n",
       "SocialSpambot 2014-11-13 06:32:37.091956736"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Promedios de fecha de recolección por categoria\n",
    "tweets.crawled_at = pd.to_datetime(tweets.crawled_at,errors='coerce')\n",
    "a = tweets[['crawled_at','Cat']]\n",
    "a.crawled_at = a.crawled_at.astype(int)\n",
    "b = a.groupby('Cat').mean()\n",
    "b.crawled_at = pd.to_datetime(b.crawled_at)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'text', 'source', 'user_id', 'truncated', 'in_reply_to_status_id',\n",
       "       'in_reply_to_user_id', 'in_reply_to_screen_name', 'retweeted_status_id',\n",
       "       'geo', 'place', 'contributors', 'retweet_count', 'reply_count',\n",
       "       'favorite_count', 'favorited', 'retweeted', 'possibly_sensitive',\n",
       "       'num_hashtags', 'num_urls', 'num_mentions', 'created_at', 'timestamp',\n",
       "       'crawled_at', 'updated', 'Cat', 'bot'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>user_id</th>\n",
       "      <th>truncated</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>geo</th>\n",
       "      <th>...</th>\n",
       "      <th>num_mentions</th>\n",
       "      <th>created_at</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>crawled_at</th>\n",
       "      <th>updated</th>\n",
       "      <th>Cat</th>\n",
       "      <th>bot</th>\n",
       "      <th>dayOfWeek</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>593932392663912449</td>\n",
       "      <td>RT @morningJewshow: Speaking about Jews and co...</td>\n",
       "      <td>&lt;a href=\"http://tapbots.com/tweetbot\" rel=\"nof...</td>\n",
       "      <td>678033.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.939322e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Fri May 01 00:18:11 +0000 2015</td>\n",
       "      <td>2015-05-01 02:18:11</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "      <td>Humans</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>18-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>593895316719423488</td>\n",
       "      <td>This age/face recognition thing..no reason pla...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>678033.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thu Apr 30 21:50:52 +0000 2015</td>\n",
       "      <td>2015-04-30 23:50:52</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "      <td>Humans</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>18-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>593880638069018624</td>\n",
       "      <td>Only upside of the moment I can think of is th...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Tw...</td>\n",
       "      <td>678033.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thu Apr 30 20:52:32 +0000 2015</td>\n",
       "      <td>2015-04-30 22:52:32</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "      <td>Humans</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>18-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593847955536252928</td>\n",
       "      <td>If you're going to think about+create experien...</td>\n",
       "      <td>&lt;a href=\"http://tapbots.com/tweetbot\" rel=\"nof...</td>\n",
       "      <td>678033.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thu Apr 30 18:42:40 +0000 2015</td>\n",
       "      <td>2015-04-30 20:42:40</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "      <td>Humans</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>18-2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>593847687847350272</td>\n",
       "      <td>Watching a thread on FB about possible future ...</td>\n",
       "      <td>&lt;a href=\"http://tapbots.com/tweetbot\" rel=\"nof...</td>\n",
       "      <td>678033.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thu Apr 30 18:41:36 +0000 2015</td>\n",
       "      <td>2015-04-30 20:41:36</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "      <td>2015-05-01 12:57:19</td>\n",
       "      <td>Humans</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>18-2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  593932392663912449  RT @morningJewshow: Speaking about Jews and co...   \n",
       "1  593895316719423488  This age/face recognition thing..no reason pla...   \n",
       "2  593880638069018624  Only upside of the moment I can think of is th...   \n",
       "3  593847955536252928  If you're going to think about+create experien...   \n",
       "4  593847687847350272  Watching a thread on FB about possible future ...   \n",
       "\n",
       "                                              source   user_id  truncated  \\\n",
       "0  <a href=\"http://tapbots.com/tweetbot\" rel=\"nof...  678033.0        NaN   \n",
       "1  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...  678033.0        NaN   \n",
       "2  <a href=\"http://twitter.com\" rel=\"nofollow\">Tw...  678033.0        NaN   \n",
       "3  <a href=\"http://tapbots.com/tweetbot\" rel=\"nof...  678033.0        NaN   \n",
       "4  <a href=\"http://tapbots.com/tweetbot\" rel=\"nof...  678033.0        NaN   \n",
       "\n",
       "   in_reply_to_status_id  in_reply_to_user_id in_reply_to_screen_name  \\\n",
       "0                    0.0                  0.0                     NaN   \n",
       "1                    0.0                  0.0                     NaN   \n",
       "2                    0.0                  0.0                     NaN   \n",
       "3                    0.0                  0.0                     NaN   \n",
       "4                    0.0                  0.0                     NaN   \n",
       "\n",
       "   retweeted_status_id  geo   ...    num_mentions  \\\n",
       "0         5.939322e+17  NaN   ...             1.0   \n",
       "1         0.000000e+00  NaN   ...             0.0   \n",
       "2         0.000000e+00  NaN   ...             0.0   \n",
       "3         0.000000e+00  NaN   ...             0.0   \n",
       "4         0.000000e+00  NaN   ...             0.0   \n",
       "\n",
       "                       created_at            timestamp           crawled_at  \\\n",
       "0  Fri May 01 00:18:11 +0000 2015  2015-05-01 02:18:11  2015-05-01 12:57:19   \n",
       "1  Thu Apr 30 21:50:52 +0000 2015  2015-04-30 23:50:52  2015-05-01 12:57:19   \n",
       "2  Thu Apr 30 20:52:32 +0000 2015  2015-04-30 22:52:32  2015-05-01 12:57:19   \n",
       "3  Thu Apr 30 18:42:40 +0000 2015  2015-04-30 20:42:40  2015-05-01 12:57:19   \n",
       "4  Thu Apr 30 18:41:36 +0000 2015  2015-04-30 20:41:36  2015-05-01 12:57:19   \n",
       "\n",
       "               updated     Cat    bot  dayOfWeek  hour  weekNum  \n",
       "0  2015-05-01 12:57:19  Humans  False          4     2  18-2015  \n",
       "1  2015-05-01 12:57:19  Humans  False          3    23  18-2015  \n",
       "2  2015-05-01 12:57:19  Humans  False          3    22  18-2015  \n",
       "3  2015-05-01 12:57:19  Humans  False          3    20  18-2015  \n",
       "4  2015-05-01 12:57:19  Humans  False          3    20  18-2015  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timedelta('0 days 00:05:11.500000')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(tweets_humans.columns)\n",
    "\n",
    "first = True\n",
    "def getDataTweets(twU):\n",
    "    global first\n",
    "    if(first):\n",
    "        dates = pd.to_datetime(twU.timestamp) #aca lo que hago es guardar la columnoa como datetime\n",
    "        twU = twU.sort_values(by='timestamp', ascending=0)\n",
    "        twU.loc[:,'dayOfWeek'] = dates.dt.dayofweek # dia de la semana\n",
    "        twU.loc[:,'hour'] = dates.dt.hour #hora del tweet\n",
    "        twU.loc[:,'weekNum'] = dates.apply(lambda x: str(x.week) + '-' + str(x.year))\n",
    "        display(twU.head())\n",
    "        \n",
    "        times = pd.to_datetime(twU.timestamp.shift(1)) - pd.to_datetime(twU.timestamp) # calculo distancia entre tweets\n",
    "        display(times.median())\n",
    "    first = False\n",
    "\n",
    "tweets_humans.groupby('user_id').apply(getDataTweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usuarios unicos en dataset de Users:  8386\n",
      "Usuarios unicos en dataset de Tweets:  5995\n"
     ]
    }
   ],
   "source": [
    "print('Usuarios unicos en dataset de Users: ',users.id.nunique())\n",
    "print('Usuarios unicos en dataset de Tweets: ',tweets.user_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Crear tabla de cuenta de tweets desde dataset de tweets\n",
    "id_count_tweets = tweets[['user_id','id']].groupby('user_id',as_index=False).count()\n",
    "id_count_tweets.rename(columns={'user_id':'id','id':'tweet_count'}, inplace=True)\n",
    "# Joinear datasets para agregar a Users la cuenta tweets\n",
    "users = users.merge(id_count_tweets,how='left',on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de usuarios sin tweets:  2391\n"
     ]
    }
   ],
   "source": [
    "print('Cantidad de usuarios sin tweets: ',users.tweet_count.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cat</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Humans</th>\n",
       "      <td>2391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id\n",
       "Cat         \n",
       "Humans  2391"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explorar usuarios sin tweets por categoria\n",
    "users[['Cat','id']][users.tweet_count.isna()].groupby('Cat').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de usuarios Humanos únicos en el dataset original:  3474\n",
      "Proporcion de usuarios humanos que tienen tweets:  0.31174438687392053\n"
     ]
    }
   ],
   "source": [
    "print('Cantidad de usuarios Humanos únicos en el dataset original: ',users[users.Cat==\"Humans\"].id.nunique())\n",
    "print('Proporcion de usuarios humanos que tienen tweets: ',tweets[tweets.Cat==\"Humans\"].user_id.nunique()/users[users.Cat==\"Humans\"].id.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza Dataset USERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columnas no utilizables\n",
    "users_ss1.drop(columns='test_set_1',inplace=True)\n",
    "users_ss3.drop(columns='test_set_2',inplace=True)\n",
    "users_humans.drop(columns=['test_set_1','test_set_2'],inplace=True)\n",
    "# rectificar formato de fecha\n",
    "users['crawled_at'] = pd.to_datetime(users['crawled_at'])\n",
    "users['updated'] = pd.to_datetime(users['updated'])\n",
    "# Procesamiento COLUMNAS\n",
    "# default_profile_image\n",
    "users.drop(columns='default_profile_image',inplace=True)  # solo 60 valores - se descarta\n",
    "# default_profile\n",
    "users.default_profile.fillna(0,inplace=True) # 1 = tema y background default de twitter   0 = modificado\n",
    "# descriptiontweets.retweeted_status_id = tweets.retweeted_status_id.notna()  # Convertir a Dummy\n",
    "users.description = users.description.notna()  # Convertir a Dummy 'tiene o no tiene descripción'\n",
    "# geo_enabled\n",
    "users.geo_enabled = users.geo_enabled.notna()  # Convertir a Dummy 'usuario con marca para agregar info geograf en posts'\n",
    "# location  -- convendrá convertirla en dummy si/no?\n",
    "# profile_background_tile\n",
    "users.profile_background_tile = users.profile_background_tile.notna()  # Convertir a Dummy\n",
    "# profile_banner_url\n",
    "users.profile_banner_url = users.profile_banner_url.notna()  # Convertir a Dummy\n",
    "# profile_use_background_imagen_reply_to_status_id.value_counts()\n",
    "users.profile_use_background_image = users.profile_use_background_image.notna()  # Convertir a Dummy\n",
    "# url\n",
    "users.url = users.url.notna()  # Convertir a Dummy\n",
    "# eliminar columnas vacías\n",
    "users.drop(columns=['contributors_enabled','follow_request_sent','following','is_translator','notifications','protected','verified'],inplace=True)\n",
    "# Corregir formato timestamp\n",
    "users.crawled_at = pd.to_datetime(users.crawled_at)\n",
    "users.timestamp = pd.to_datetime(users.timestamp)\n",
    "users.updated = pd.to_datetime(users.updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza Dataset TWEETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columnas vacías o con muy pocos valores\n",
    "tweets.drop(columns=['truncated','geo','contributors','favorited','retweeted','possibly_sensitive','place'],inplace=True)\n",
    "# source\n",
    "tweets.drop(columns=['source'],inplace=True)   # No utilizable\n",
    "# in_reply_to_screen_name & in_reply_to_status_id \n",
    "tweets.drop(columns=['in_reply_to_screen_name'],inplace=True)   # nos quedamos con in reply user id\n",
    "tweets.drop(columns=['in_reply_to_status_id'],inplace=True)   # nos quedamos con in reply user id\n",
    "# in_reply_to_user_id\n",
    "tweets.in_reply_to_user_id = tweets.in_reply_to_user_id.notna()  # Convertir a Dummy\n",
    "# retweeted_status_id\n",
    "tweets.retweeted_status_id = tweets.retweeted_status_id.notna()  # Convertir a Dummy\n",
    "# Corregir formato timestamp\n",
    "tweets.crawled_at = pd.to_datetime(tweets.crawled_at)\n",
    "tweets.timestamp = pd.to_datetime(tweets.timestamp)\n",
    "tweets.updated = pd.to_datetime(tweets.updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de usuarios humanos válidos con tweets: 1083\n",
      "Cantidad de tweets: 2839361\n"
     ]
    }
   ],
   "source": [
    "# Nos quedamos solo con los usuarios humanos que tienen tweets\n",
    "users[users.Cat=='Humans'] = users[users.Cat=='Humans'][users.id.isin(tweets.user_id)]\n",
    "# Y con los tweets de esos usuarios\n",
    "tweets[tweets.Cat=='Humans'] = tweets[tweets.user_id.isin(users.id[users.Cat=='Humans'])]\n",
    "print('Cantidad de usuarios humanos válidos con tweets:',users.id[users.Cat=='Humans'].nunique())\n",
    "print('Cantidad de tweets:',tweets.id[tweets.Cat=='Humans'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de usuarios bot válidos con tweets: 4912\n",
      "Cantidad de tweets: 3457133\n"
     ]
    }
   ],
   "source": [
    "# Nos quedamos solo con los usuarios bots que tienen tweets\n",
    "users[users.Cat=='SocialSpambot'] = users[users.Cat=='SocialSpambot'][users.id.isin(tweets.user_id)]\n",
    "# Y con los tweets de esos usuarios\n",
    "tweets[tweets.Cat=='SocialSpambot'] = tweets[tweets.user_id.isin(users.id[users.Cat=='SocialSpambot'])]\n",
    "print('Cantidad de usuarios bot válidos con tweets:',users.id[users.Cat=='SocialSpambot'].nunique())\n",
    "print('Cantidad de tweets:',tweets.id[tweets.Cat=='SocialSpambot'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de usuarios bot válidos con tweets: 1100\n",
      "Cantidad de tweets: 780097\n"
     ]
    }
   ],
   "source": [
    "# Para balancear, tomamos una muestra de spambots y sus respectivos tweets\n",
    "users[users.Cat=='SocialSpambot'] = users[users.Cat=='SocialSpambot'].sample(1100)   # Muestra 1100\n",
    "# Y con los tweets de esos usuarios\n",
    "tweets[tweets.Cat=='SocialSpambot'] = tweets[tweets.user_id.isin(users.id[users.Cat=='SocialSpambot'])]\n",
    "print('Cantidad de usuarios bot válidos con tweets:',users.id[users.Cat=='SocialSpambot'].nunique())\n",
    "print('Cantidad de tweets:',tweets.id[tweets.Cat=='SocialSpambot'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dump de ambos datastes to pickle\n",
    "users.to_pickle('users.pkl')\n",
    "#tweets.to_csv('tweets.csv') # OJO - Genera un archivo de casi 1 giga "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
